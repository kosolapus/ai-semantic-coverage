##  **Solution Brief: Semantic Coverage через семантические интенты (предполагаемые намерения)**

#### **1. Постановка проблемы**
В современных проектах автотесты редко явно привязаны к бизнес-требованиям. Это создаёт **разрыв между намерением 
(requirement)** и **реализацией проверки (test)**. Проблема усугубляется тем, что:
- Требования часто неформализованы или написаны в бизнес-терминах,
- Код и тесты выражены в технических терминах,
- Семантическое расстояние между этими двумя плоскостями делает прямое сопоставление (через ключевые слова или 
простые эмбеддинги) неэффективным.

Цель решения — построить **AI-систему**, которая автоматически определяет степень покрытия требований тестами 
на основе **семантического сходства их намерений**, а не поверхностных признаков.

---

#### **2. Архитектура и подход**
Я предложил **трёхэтапный pipeline**, основанный на гипотезе: *«Если привести требования и тесты к общей форме 
выражения намерений, их можно сопоставить через семантический поиск»*.

##### **Этап 1. Извлечение интента**

Для каждого требования и тестового файла используется **LLM (rnj-1:8b-cloud)** для генерации **структурированного 
интента** в формате **5W1H** (Who, What, When, Where, Why, How).

Пример:  
```
  Требование: «Пользователь может вызвать инструмент через MCP»  
  Интент: { what: "вызов инструмента", who: "пользователь", how: "через MCP-протокол" }.
```

Кроме того, на этом же этапе извлекаются дополнительные данные для дальнейшего анализа и улучшения:
- Для тестов формируются файлы-родители
- Требования разбиваются на интенты по принципу "у одного зафиксированного требования должно быть не менее одного 
интента"

##### **Этап 2. Векторизация и поиск кандидатов**
- Интенты эмбеддятся с помощью **embeddinggemma**.
- Для каждого требования выполняется отбор интентов, сформированных из него. 
- Для каждого интента выполняется  **векторный поиск** среди интентов тестов → выбираются top-k кандидатов.
- Это снижает шум по сравнению с прямой векторизацией исходного кода/требований (эксперимент показал: без 
нормализации интента кластеры формируются по типу файла, а не по смыслу).

##### **Этап 3. Оценка покрытия и объяснение**

- Все найденные соответсвия по иерархии "Требование" -- "Интент" -- "Кандидат теста" передаются в **LLM (qwen3-next:80b-cloud)**
- LLM формирует итоговый отчет, определяя, относится ли конкретный кандидат в тесты к покрытию исходного требования
- На основании текста требования, количества тестов и данных самих тестов LLM выстраивает утверждения о том, насколько
указанное требование покрывается тестами (градация `none`, `partial`, `good`, `full`)

---

#### **3. Обоснование жизнеспособности и компромиссы**
Для эксперимента был выбран репозиторий [`rekog-labs/MCP-Nest`](https://github.com/rekog-labs/MCP-Nest.git), 
сформулировано **16 требований** (10 — на основе анализа кода, 6 — контрольные).

Подход подтверждён серией экспериментов на репозитории:
- Из 164 файлов репозитория отобран и обработан **31 тестовый файл**.
- Система корректно определила покрытие **15/16 требований**: 
  - **7 помечены как «none»** (отсутствие покрытия, не найдено тестов со схожим интентом). 
  - **1 помечен как «partial»** (частичное покрытие, тесты покрывают не весь интент требования).
  - **8 помечены как «full»** (полное покрытие, 1+ тестов для подтверждения).
- Система не смогла найти соответствие для одного из требований, несмотря на наличие теста на эту функциональность.


**Ключевые компромиссы:**

В условиях ограниченности времени и слишком широкого спектра доступных ресурсов, многие аспекты были сознательно упущены, 
а некоторые просто не укладывались в требуемый срок:

- Отказ от глубокого статического анализа кода в пользу LLM-интентов
- Отказ от экспериментов с другими форматами интентов (ГОСТ/ieee)
- Отказ от построения семантического графа смыслов для дополнения интента из родительских блоков
- Доверие результатам генерации извлеченных смыслов от LLM без дополнительных проверок
- Отказ от математического обоснования итоговой оценки покрытия (0-100 шкала)
- Отказ от глубоких экспериментов с prompt-engeneering'ом

---

#### **4. Ограничения и пути митигации**
| Риск                                | Причина                                                                                                   | Митигация (в будущем)                                                                                                                                 |
|-------------------------------------|-----------------------------------------------------------------------------------------------------------|-------------------------------------------------------------------------------------------------------------------------------------------------------|
| Галлюцинации при извлечении интента | LLM может "додумать" несуществующее поведение                                                             | Ввести cross-check: сравнение интентов через embedding + rule-based sanity check                                                                      |
| Неполный сбор тестов                | Фильтрация по `test`/`spec` в путях                                                                       | Интеграция с тест-раннерами (Jest, PyTest) для точного списка                                                                                         |
| Зависимость от формулировок         | Расплывчатые требования → низкий score                                                                    | Предлагать авторам канонические формулировки                                                                                                          |
| Нестабильность при смене модели     | Некоторые модели склонны к фантазиям на этапе оценки                                                      | Использовать только embedding + threshold для coarse-grained, LLM — только для final explanation                                                      |
| Недетерминированность результата    | Выход LLM зависит от модели, промпта, температуры; разные модели дают качественно разные интенты и оценки | Перейти от полной зависимости от LLM к гибридной оценке: embedding-based similarity + rule-based sanity checks + LLM только для финального объяснения |
---

### Приложения:  

1. Результаты эмбеддинга "в лоб" [Изображение](./0.first_attempt_no_chunking.png)
2. Результаты эмбеддинга с извлечением типов [Изображение](./1.type_detection.png)
3. Результаты эмбеддинга при использовании 8b модели без доработок промптов [Изображение](./2.simple_model_chunking.png)
4. Результаты эмбеддинга при использовании 80b модели без доработок промптов [Изображение](./3.heavy_model_with_prompts.png)
5. Результаты эмбеддинга при использовании 8b модели с доработанными промптами [Изображение](./4.8b_model_with_prompts.png)
6. Эксперимент на другом случайном репозитории (8b + prompts)  [Изображение](./5.another_repository.png)

#### Таблицы с отчетами:

Отчеты формировались на основе 2 выборок данных - `8b + prompts` и `80b`
1. `80b` + gpt 5.2: [Отчет](./result/1.result_gpt5.2.md)
2. `80b` + 80b: [Отчет](./result/2.result_qwen80b.md)
3. `8b + prompts` + 80b: [Отчет](./result/3.result_qwen_80b_with_8b_chunking.md)
4. _(Повысил порог доверия результатам, ограничил выборку пар тест - требование)_ `8b + prompts` + 8b: [Отчет](./result/4.increase_treshold.md)
5. _(Повысил порог доверия результатам, ограничил выборку пар тест - требование)_ `8b + prompts` + 80b: [Отчет](./result/5.treshold_0_5_qwen80b.md)
6. Эксперимент на другом случайном репозитории (8b + prompts) [Отчет](./result/6.another_repository_result.md)

[Список требований к исследуемому репозиторию](./req.md)
